{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f2244f11eab922",
   "metadata": {},
   "source": [
    "# Qdrant indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d321e6755b15e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:34:55.653622Z",
     "start_time": "2024-07-15T09:34:46.580296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffb540136af44beb9f57fcffe57f904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6d32ade33e4c9589d1790b22b70c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/5183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'_id': '4983',\n",
       " 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.',\n",
       " 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"BeIR/scifact\", \"corpus\", split=\"corpus\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26797f7a57adc4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:34:55.657745Z",
     "start_time": "2024-07-15T09:34:55.654856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5183"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976c453bf0d27c0",
   "metadata": {},
   "source": [
    "## Dense embeddings\n",
    "\n",
    "We're not going to choose the fanciest embedding model out there, but stick to something simple and efficient. FastEmbed comes with some pretrained models that we can use out of the box. Due to ONNX usage, these models can be launched efficiently even on a CPU. The `all-MiniLM-L6-v2` model is a lightweight model that's good for a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611ad98114d793b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:47:53.926605Z",
     "start_time": "2024-07-15T09:42:24.389900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c5a1b6092b457e8f6bead0826b8318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "dense_embedding_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "dense_embeddings = list(dense_embedding_model.passage_embed(dataset[\"text\"][0:1]))\n",
    "len(dense_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702cbdb3d2c6a32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:30:49.594058Z",
     "start_time": "2024-07-15T11:30:49.587212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dense_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74386f75bb96941",
   "metadata": {},
   "source": [
    "## Sparse embeddings\n",
    "\n",
    "Similarly, we can use a BM25 model to generate sparse embeddings, so it hopefully will handle the cases in which the dense embeddings fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bc60aa2d0956d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:58:19.415397Z",
     "start_time": "2024-07-15T09:58:15.358148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e67bb335e254321b8d66e728c82373a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 29 files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3558bf74bb4a8c870d94ae1a569817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "catalan.txt:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8d4e2287dc4b03a5b77d0b67c5da6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "arabic.txt:   0%|          | 0.00/6.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1a3c0637044a2887a2dd9ded8d6ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "azerbaijani.txt:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6655f44a177649639ac99676842dabf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dutch.txt:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3434a497a95d43b99951729286f13b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "basque.txt:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f97d16394f643aa8039d7ceb6418cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bengali.txt:   0%|          | 0.00/5.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb378aa035047f28f44f6203adc2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chinese.txt:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55512498a09f42458789f0b7b5205fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "danish.txt:   0%|          | 0.00/424 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342fc820565c4d26b03c61b6a48be596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "english.txt:   0%|          | 0.00/936 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0d575922194ef7af8b69eb8552eb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "german.txt:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4772d73e2b214ccc89726cb54a6f4cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hinglish.txt:   0%|          | 0.00/5.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2edb2398454c3c862d24a97dda43b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "greek.txt:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc75f2b749240fc9e3f6177dc2a78b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hungarian.txt:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2effdfe15a44bdfbceebe4e10cf4830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "finnish.txt:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a139eba7008643efa5f186062294f7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hebrew.txt:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f8443812f64b4abbab41befb236da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french.txt:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf2e5939ba04971adab7326cedc45ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kazakh.txt:   0%|          | 0.00/3.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df80aa83a5c34faea559002d1b48d47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "romanian.txt:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126ce9142457418db66ca7db57352d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "nepali.txt:   0%|          | 0.00/3.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c1be8adce400f8c8a78dfdcb00290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "russian.txt:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d0618850fe4b5eb2779eca629480d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "portuguese.txt:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fda13ea8249403c9d3fab022109a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norwegian.txt:   0%|          | 0.00/851 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c64554d885434d85075077603ca8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indonesian.txt:   0%|          | 0.00/6.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8445c696302e4221983209345f9835a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "italian.txt:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfc69f0c066449b80c7d3d9d161e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tajik.txt:   0%|          | 0.00/1.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749aa5bdf78f4531807d8faf36d43e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "turkish.txt:   0%|          | 0.00/260 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef85c1aa7c2d4ad8978c5f2f5028bd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "slovene.txt:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769dcff8013c460aa72ee2cd30be1b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "swedish.txt:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a45ae1a9ff40f78d6e47a7aad59a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spanish.txt:   0%|          | 0.00/2.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "bm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")\n",
    "bm25_embeddings = list(bm25_embedding_model.passage_embed(dataset[\"text\"][0:1]))\n",
    "len(bm25_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443ae4affae64c6",
   "metadata": {},
   "source": [
    "## Late interaction embeddings\n",
    "\n",
    "Both dense and sparse embeddings we generated so far produce a single embedding per document. However, there is also a different approach, where we can generate a single embedding per token. For each query token we take its maximum similarity against the document and sum across query terms. This kind of models is called late interaction models, and ColBERT is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a177b683a57aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:41:37.087598Z",
     "start_time": "2024-07-15T10:12:33.013136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1600ec5021c9442bbe72395e117d3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import LateInteractionTextEmbedding\n",
    "\n",
    "late_interaction_embedding_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n",
    "late_interaction_embeddings = list(late_interaction_embedding_model.passage_embed(dataset[\"text\"][0:1]))\n",
    "len(late_interaction_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e0690fdd4c36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:30:39.061309Z",
     "start_time": "2024-07-15T11:30:39.056798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(late_interaction_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fbac945e35a55",
   "metadata": {},
   "source": [
    "## Putting data in a Qdrant collection\n",
    "\n",
    "All the vectors might be now upserted into a Qdrant collection. Keeping them all in a single one enables the possibility to combine different embeddings and create even a complex pipeline with several steps. Depending on the specifics of your data, you may prefer to use a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431ec613-ad0c-4a35-b0da-bb2f69294999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'qdrant/qdrant:v1.10.0' locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.10.0: Pulling from qdrant/qdrant\n",
      "\n",
      "\u001b[1B76444520: Pulling fs layer \n",
      "\u001b[1B3062c8bc: Pulling fs layer \n",
      "\u001b[1B3168c290: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1Bd049bab8: Pulling fs layer \n",
      "\u001b[1Be2b94493: Pulling fs layer \n",
      "\u001b[1B5ed2089d: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:2e8646f963a64a21b3e3f851719e17668644d1ed386285064c2548a52d16ede8[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2KDownload complete \u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for qdrant/qdrant:v1.10.0\n",
      "c91c886ff8283dbbeffb6a150c98445b065256485fb6a9ecbde5322ed0ced000\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint thirsty_jang (1b7a76c83d0b3e8ddcd5f4fdce95669a6541b6db4a23eb519ba359258c22775f): Bind for 0.0.0.0:6334 failed: port is already allocated.\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 6333:6333 -p 6334:6334 qdrant/qdrant:v1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0ba5b8b767ae5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:35:45.875085Z",
     "start_time": "2024-07-15T11:35:45.785286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\", timeout=600)\n",
    "client.create_collection(\n",
    "    \"scifact\",\n",
    "    vectors_config={\n",
    "        \"all-MiniLM-L6-v2\": models.VectorParams(\n",
    "            size=len(dense_embeddings[0]),\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "        \"colbertv2.0\": models.VectorParams(\n",
    "            size=len(late_interaction_embeddings[0][0]),\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            )\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238650e7e3ea136e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-15T11:53:37.675152Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1296it [22:14,  1.03s/it]                                                                                        \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "batch_size = 4\n",
    "for batch in tqdm.tqdm(dataset.iter(batch_size=batch_size), \n",
    "                       total=len(dataset) // batch_size):\n",
    "    dense_embeddings = list(dense_embedding_model.passage_embed(batch[\"text\"]))\n",
    "    bm25_embeddings = list(bm25_embedding_model.passage_embed(batch[\"text\"]))\n",
    "    late_interaction_embeddings = list(late_interaction_embedding_model.passage_embed(batch[\"text\"]))\n",
    "    \n",
    "    client.upload_points(\n",
    "        \"scifact\",\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=int(batch[\"_id\"][i]),\n",
    "                vector={\n",
    "                    \"all-MiniLM-L6-v2\": dense_embeddings[i].tolist(),\n",
    "                    \"bm25\": bm25_embeddings[i].as_object(),\n",
    "                    \"colbertv2.0\": late_interaction_embeddings[i].tolist(),\n",
    "                },\n",
    "                payload={\n",
    "                    \"_id\": batch[\"_id\"][i],\n",
    "                    \"title\": batch[\"title\"][i],\n",
    "                    \"text\": batch[\"text\"][i],\n",
    "                }\n",
    "            )\n",
    "            for i, _ in enumerate(batch[\"_id\"])\n",
    "        ],\n",
    "        # We send a lot of embeddings at once, so it's best to reduce the batch size.\n",
    "        # Otherwise, we would have gigantic requests sent for each batch and we can\n",
    "        # easily reach the maximum size of a single request.\n",
    "        batch_size=batch_size,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae256b5-b874-41e4-b633-85c16f29f2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.recover_snapshot(\n",
    "    \"scifact\",\n",
    "    location=\"https://storage.googleapis.com/common-datasets-snapshots/scifact-multiple-representations.snapshot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8154fe8e865a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=15549, points_count=5183, segments_count=7, config=CollectionConfig(params=CollectionParams(vectors={'all-MiniLM-L6-v2': VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), 'colbertv2.0': VectorParams(size=128, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=MultiVectorConfig(comparator=<MultiVectorComparator.MAX_SIM: 'max_sim'>))}, shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors={'bm25': SparseVectorParams(index=None, modifier=<Modifier.IDF: 'idf'>)}), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(\"scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84203d-8ecb-4d8e-bd00-a18ec524cf52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
